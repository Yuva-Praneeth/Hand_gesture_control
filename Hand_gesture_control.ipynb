{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f92ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ad1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5857548",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)# Initialize video capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db88a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_width, screen_height = pyautogui.size()# Get screen dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00416675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for cursor control\n",
    "cursor_smoothing = 0.5  # Smoothing factor (0-1)\n",
    "prev_cursor_x, prev_cursor_y = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adfcb948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for hover selection\n",
    "hover_start_time = 0\n",
    "hover_position = None\n",
    "hover_threshold = 5  # 5 seconds for selection\n",
    "hover_radius = 15  # pixels of movement allowed during hove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732b4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for open palm detection\n",
    "palm_open_start_time = 0\n",
    "palm_open_detected = False\n",
    "palm_open_threshold = 5  # 5 seconds for minimize all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58833976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for swipe gesture\n",
    "swipe_start_position = None\n",
    "swipe_threshold = 100  # pixels for minimum swipe distance\n",
    "swipe_cooldown = 0  # cooldown timer to prevent multiple swipes\n",
    "swipe_cooldown_threshold = 2  # seconds between swipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b170bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyautogui settings for safety\n",
    "pyautogui.FAILSAFE = True\n",
    "pyautogui.PAUSE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899dc789",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Read frame from video capture\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Flip the frame horizontally for a more intuitive experience\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "    # Convert the BGR frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame with Mediapipe hands\n",
    "    results = hands.process(frame_rgb)\n",
    "    \n",
    "    # Current cursor position\n",
    "    cursor_x, cursor_y = None, None\n",
    "    \n",
    "    # Current time for timing functions\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Decrease swipe cooldown if active\n",
    "    if swipe_cooldown > 0:\n",
    "        swipe_cooldown = max(0, swipe_cooldown - 0.03)  # decrease by ~30ms per frame\n",
    "    \n",
    "    # Check if hands are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draw landmarks on the hand\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, \n",
    "                hand_landmarks, \n",
    "                mp_hands.HAND_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            # Get the palm landmark\n",
    "            palm_landmark = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]\n",
    "            palm_x = int(palm_landmark.x * frame_width)\n",
    "            palm_y = int(palm_landmark.y * frame_height)\n",
    "            \n",
    "            # Draw a circle to represent the palm\n",
    "            cv2.circle(frame, (palm_x, palm_y), 10, (0, 255, 0), -1)\n",
    "            \n",
    "            # Add green dots at fingertips\n",
    "            fingertip_indices = [\n",
    "                mp_hands.HandLandmark.THUMB_TIP,\n",
    "                mp_hands.HandLandmark.INDEX_FINGER_TIP, \n",
    "                mp_hands.HandLandmark.MIDDLE_FINGER_TIP,\n",
    "                mp_hands.HandLandmark.RING_FINGER_TIP,\n",
    "                mp_hands.HandLandmark.PINKY_TIP\n",
    "            ]\n",
    "            \n",
    "            for tip_idx in fingertip_indices:\n",
    "                fingertip = hand_landmarks.landmark[tip_idx]\n",
    "                fingertip_x = int(fingertip.x * frame_width)\n",
    "                fingertip_y = int(fingertip.y * frame_height)\n",
    "                cv2.circle(frame, (fingertip_x, fingertip_y), 8, (0, 255, 0), -1)\n",
    "            \n",
    "            # Get index finger tip for cursor control\n",
    "            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            index_x = int(index_tip.x * frame_width)\n",
    "            index_y = int(index_tip.y * frame_height)\n",
    "            \n",
    "            # Calculate cursor position (map from camera coordinates to screen coordinates)\n",
    "            cursor_x = int(index_tip.x * screen_width)\n",
    "            cursor_y = int(index_tip.y * screen_height)\n",
    "            \n",
    "            # Apply smoothing if previous position exists\n",
    "            if prev_cursor_x is not None and prev_cursor_y is not None:\n",
    "                cursor_x = int(cursor_smoothing * cursor_x + (1 - cursor_smoothing) * prev_cursor_x)\n",
    "                cursor_y = int(cursor_smoothing * cursor_y + (1 - cursor_smoothing) * prev_cursor_y)\n",
    "            \n",
    "            # Update previous cursor position\n",
    "            prev_cursor_x, prev_cursor_y = cursor_x, cursor_y\n",
    "            \n",
    "            # Move the cursor\n",
    "            try:\n",
    "                pyautogui.moveTo(cursor_x, cursor_y)\n",
    "            except pyautogui.FailSafeException:\n",
    "                pass  # Ignore if cursor moves to corner (failsafe triggered)\n",
    "            \n",
    "            # Hover selection logic\n",
    "            if hover_position is not None:\n",
    "                hover_x, hover_y = hover_position\n",
    "                # Calculate distance from current position to hover start position\n",
    "                hover_distance = np.sqrt((cursor_x - hover_x)**2 + (cursor_y - hover_y)**2)\n",
    "                \n",
    "                # If moved too far, reset hover\n",
    "                if hover_distance > hover_radius:\n",
    "                    hover_position = None\n",
    "                    hover_start_time = 0\n",
    "                # If hovered long enough, perform click\n",
    "                elif current_time - hover_start_time >= hover_threshold:\n",
    "                    # Perform click\n",
    "                    try:\n",
    "                        pyautogui.click()\n",
    "                        # Visual feedback for click\n",
    "                        cv2.circle(frame, (index_x, index_y), 30, (0, 0, 255), 5)\n",
    "                    except pyautogui.FailSafeException:\n",
    "                        pass  # Ignore failsafe\n",
    "                    \n",
    "                    # Reset hover timer\n",
    "                    hover_position = None\n",
    "                    hover_start_time = 0\n",
    "                else:\n",
    "                    # Still hovering, show progress\n",
    "                    hover_progress = (current_time - hover_start_time) / hover_threshold\n",
    "                    radius = int(30 * hover_progress)\n",
    "                    cv2.circle(frame, (index_x, index_y), radius, (255, 0, 0), 2)\n",
    "            \n",
    "            # If no hover position yet, start new hover\n",
    "            elif hover_position is None:\n",
    "                hover_position = (cursor_x, cursor_y)\n",
    "                hover_start_time = current_time\n",
    "            \n",
    "            # Check for open palm gesture\n",
    "            # Get finger MCP points (knuckles)\n",
    "            finger_mcp_indices = [\n",
    "                mp_hands.HandLandmark.THUMB_CMC,\n",
    "                mp_hands.HandLandmark.INDEX_FINGER_MCP,\n",
    "                mp_hands.HandLandmark.MIDDLE_FINGER_MCP,\n",
    "                mp_hands.HandLandmark.RING_FINGER_MCP,\n",
    "                mp_hands.HandLandmark.PINKY_MCP\n",
    "            ]\n",
    "            \n",
    "            # Get finger tip positions\n",
    "            finger_tips = [hand_landmarks.landmark[i] for i in fingertip_indices]\n",
    "            finger_mcps = [hand_landmarks.landmark[i] for i in finger_mcp_indices]\n",
    "            \n",
    "            # Check if palm is open (all fingers extended)\n",
    "            is_palm_open = True\n",
    "            for tip, mcp in zip(finger_tips, finger_mcps):\n",
    "                # Skip thumb as it behaves differently\n",
    "                if tip == finger_tips[0]:\n",
    "                    continue\n",
    "                \n",
    "                # Check if finger is extended by ensuring tip is above mcp (y is smaller since origin is top-left)\n",
    "                if tip.y > mcp.y:\n",
    "                    is_palm_open = False\n",
    "                    break\n",
    "            \n",
    "            # Check pinky and index finger horizontal distance for wide-open palm\n",
    "            pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            fingers_spread = abs(pinky_tip.x - index_tip.x) > 0.2  # threshold for spread fingers\n",
    "            \n",
    "            is_palm_open = is_palm_open and fingers_spread\n",
    "            \n",
    "            # Palm open status and time tracking\n",
    "            if is_palm_open:\n",
    "                if not palm_open_detected:\n",
    "                    palm_open_start_time = current_time\n",
    "                    palm_open_detected = True\n",
    "                \n",
    "                # Check if palm has been open for threshold time\n",
    "                if current_time - palm_open_start_time >= palm_open_threshold:\n",
    "                    # Minimize all windows\n",
    "                    pyautogui.hotkey('win', 'd')\n",
    "                    \n",
    "                    # Visual feedback\n",
    "                    cv2.putText(frame, \"Minimizing all windows!\", (50, frame_height - 50), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    \n",
    "                    # Reset timer to prevent multiple actions\n",
    "                    palm_open_start_time = current_time + 5  # Add 5 seconds cooldown\n",
    "                \n",
    "                # Show progress for palm open gesture\n",
    "                palm_progress = min(1.0, (current_time - palm_open_start_time) / palm_open_threshold)\n",
    "                progress_bar_width = int(frame_width * palm_progress)\n",
    "                cv2.rectangle(frame, (0, frame_height - 20), (progress_bar_width, frame_height), (0, 255, 0), -1)\n",
    "                cv2.putText(frame, \"Palm Open\", (10, frame_height - 30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            else:\n",
    "                palm_open_detected = False\n",
    "            \n",
    "            # Swipe detection - left to right to change tabs\n",
    "            if is_palm_open and swipe_cooldown <= 0:\n",
    "                if swipe_start_position is None:\n",
    "                    swipe_start_position = (palm_x, palm_y)\n",
    "                else:\n",
    "                    # Calculate horizontal movement\n",
    "                    swipe_distance_x = palm_x - swipe_start_position[0]\n",
    "                    \n",
    "                    # Check if hand moved significantly horizontally\n",
    "                    if abs(swipe_distance_x) > swipe_threshold:\n",
    "                        # Left to right swipe\n",
    "                        if swipe_distance_x > 0:\n",
    "                            # Switch to next tab with Ctrl+Tab\n",
    "                            pyautogui.hotkey('ctrl', 'tab')\n",
    "                            cv2.putText(frame, \"Next Tab\", (50, 120), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                        # Right to left swipe\n",
    "                        else:\n",
    "                            # Switch to previous tab with Ctrl+Shift+Tab\n",
    "                            pyautogui.hotkey('ctrl', 'shift', 'tab')\n",
    "                            cv2.putText(frame, \"Previous Tab\", (50, 120), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                        \n",
    "                        # Reset swipe detection and set cooldown\n",
    "                        swipe_start_position = None\n",
    "                        swipe_cooldown = swipe_cooldown_threshold\n",
    "            else:\n",
    "                swipe_start_position = None\n",
    "            \n",
    "            # Display cursor position\n",
    "            cv2.putText(frame, f\"Cursor: ({cursor_x}, {cursor_y})\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    else:\n",
    "        # Reset palm open detection if no hand is detected\n",
    "        palm_open_detected = False\n",
    "        swipe_start_position = None\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Hand Gesture Controls', frame)\n",
    "    \n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c418c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cf105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a04c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed40bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a14ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b11357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6c7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
